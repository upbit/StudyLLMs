{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c89068e7-337f-4671-b75f-b4b3304df378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airoboros-c34b-2.1.Q5_K_S.gguf',\n",
       " 'all-mpnet-base-v2',\n",
       " 'gpt-3.5-turbo',\n",
       " 'text-embedding-ada-002',\n",
       " 'airoboros-c34b-2.1.Q5_K_S.gguf',\n",
       " 'airoboros-l2-13b-2.1.Q5_K_M.gguf',\n",
       " 'TheBloke_Llama-2-13B-GPTQ',\n",
       " 'TheBloke_OpenAssistant-Llama2-13B-Orca-8K-3319-GPTQ',\n",
       " 'TheBloke_Wizard-Vicuna-30B-Uncensored-GPTQ',\n",
       " 'THUDM_chatglm2-6b',\n",
       " 'THUDM_chatglm-6b',\n",
       " 'wizardcoder-python-34b-v1.0.Q4_K_M.gguf']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get('http://127.0.0.1:5000/v1/models')\n",
    "models = [\n",
    "    model['id']\n",
    "    for model in r.json()['data']\n",
    "]\n",
    "\n",
    "model_name = models[0] # select first\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cca78e87-1317-4334-acd0-716a555284b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"function\": \"points_analysis\",\n",
      "  \"parameters\": {\n",
      "    \"content\": \"The text you want to analyze\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_base = \"http://127.0.0.1:5000/v1\"\n",
    "\n",
    "# create a chat completion\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=model_name,\n",
    "  tempture=0.6,\n",
    "  top_p=0.5,\n",
    "  max_tokens=500,\n",
    "  repeat_penalty=1,\n",
    "  messages=[{\"role\": \"user\", \"content\": \"\"\"As an AI assistant, please select the most suitable function and parameters from the list of available functions below, based on the user's input. Your response should be in JSON format.\n",
    "\n",
    "Input: Extract 4 main points of view in the text, and Google search for each point of view in text.\n",
    "\n",
    "Available functions:\n",
    "points_analysis:\n",
    "  description: his tool extract the points of view in given content.\n",
    "  parameters:\n",
    "    content: The phrase or document to analyze.\n",
    "google_search:\n",
    "  description: Help the user find information by converting the input query into a series of search terms and filters that may help pinpoint the location of the information.\n",
    "  parameters:\n",
    "    search_terms: List of keywords and/or phrases that are of high importance to the input.\n",
    "    alternatives: List of alternative keywords and/or phrases that are of high importance to the input, which are variations of the actual input keywords/phrases. For example, acronyms, common alternate synonyms, etc.\n",
    "\"\"\"}]\n",
    ")\n",
    "# print the completion\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0adeac17-3a90-4e08-ba37-c0f9d222eb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract the points of view in following content, into keywords and/or phrases that are of high importance to the given content.\n",
      "\n",
      "Content:\n",
      "In the world of language models, a prompt is a piece of text that instructs the model to generate a specific type of response.\n",
      "A prompt template, as the name suggests, is a reproducible way to generate such prompts. It's essentially a text string that can take in a set of parameters from the end user and generate a prompt accordingly.\n",
      "A prompt template can contain instructions for the language model, a set of few-shot examples to guide the model's response, and a question for the model.\n",
      "In conclusion, prompt templates in LangChain are a powerful tool for generating dynamic prompts for languagemodels. They offer flexibility and control over the prompts,\n",
      "allowing you to guide the model’s responses effectively. Whether you’re creating a language model for a specific task or exploring the capabilities of language models, prompt templates can be a game-changer.\n",
      "\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"search_terms\": {\"title\": \"Search Terms\", \"description\": \"List of keywords and/or phrases that are of high importance to the input\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}, \"alternatives\": {\"title\": \"Alternatives\", \"description\": \"List of alternative keywords and/or phrases that are of high importance to the input, which are variations of the actual input keywords/phrases. For example, acronyms, common alternate synonyms, etc\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"search_terms\", \"alternatives\"]}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List\n",
    "\n",
    "class GoogleSearch(BaseModel):\n",
    "    search_terms: List[str] = Field(description=\"List of keywords and/or phrases that are of high importance to the input\")\n",
    "    alternatives: List[str] = Field(description=\"List of alternative keywords and/or phrases that are of high importance to the input, \" + \\\n",
    "                                                \"which are variations of the actual input keywords/phrases. For example, acronyms, common alternate synonyms, etc\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator(\"search_terms\")\n",
    "    def search_terms_validation(cls, field):\n",
    "        if len(field) > 10:\n",
    "            raise ValueError(\"Max search terms limit reached (<=10) \")\n",
    "        return field\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=GoogleSearch)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Extract the points of view in following content, into keywords and/or phrases that are of high importance to the given content.\\n\\nContent:\\n{content}\\n\\n{format_instructions}\\n\",\n",
    "    input_variables=[\"content\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "_input = prompt.format_prompt(content=\"\"\"In the world of language models, a prompt is a piece of text that instructs the model to generate a specific type of response.\n",
    "A prompt template, as the name suggests, is a reproducible way to generate such prompts. It's essentially a text string that can take in a set of parameters from the end user and generate a prompt accordingly.\n",
    "A prompt template can contain instructions for the language model, a set of few-shot examples to guide the model's response, and a question for the model.\n",
    "In conclusion, prompt templates in LangChain are a powerful tool for generating dynamic prompts for languagemodels. They offer flexibility and control over the prompts,\n",
    "allowing you to guide the model’s responses effectively. Whether you’re creating a language model for a specific task or exploring the capabilities of language models, prompt templates can be a game-changer.\"\"\")\n",
    "print(_input.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34b1fd42-5bc0-40b0-bdac-0f44abbee90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"properties\": {\n",
      "    \"search_terms\": [\n",
      "      \"point of view\",\n",
      "      \"perspective\",\n",
      "      \"opinion\",\n",
      "      \"view\"\n",
      "    ],\n",
      "    \"alternatives\": [\n",
      "      \"outlook\",\n",
      "      \"standpoint\",\n",
      "      \"stance\",\n",
      "      \"attitude\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "openai.api_base = \"http://127.0.0.1:5000/v1\"\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature = 0.2)\n",
    "\n",
    "output = model([SystemMessage(content=\"As an AI assistant, please select the most suitable function and parameters from the list of available functions below, based on the user's input. Provide your response in JSON format.\"),\n",
    "                HumanMessage(content=_input.to_string())])\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f9ed01c-6f30-4b19-98d8-861479a60bfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Failed to parse GoogleSearch from completion {\n  \"properties\": {\n    \"search_terms\": [\n      \"points of view\",\n      \"keywords and/or phrases that are of high importance to the given content\"\n    ],\n    \"alternatives\": []\n  },\n  \"required\": [\"search_terms\"]\n}. Got: 2 validation errors for GoogleSearch\nsearch_terms\n  field required (type=value_error.missing)\nalternatives\n  field required (type=value_error.missing)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\torch\\Lib\\site-packages\\langchain\\output_parsers\\pydantic.py:29\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     28\u001b[0m     json_object \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(json_str, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpydantic_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_object\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (json\u001b[38;5;241m.\u001b[39mJSONDecodeError, ValidationError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\.conda\\envs\\torch\\Lib\\site-packages\\pydantic\\main.py:526\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.parse_obj\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\.conda\\envs\\torch\\Lib\\site-packages\\pydantic\\main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 2 validation errors for GoogleSearch\nsearch_terms\n  field required (type=value_error.missing)\nalternatives\n  field required (type=value_error.missing)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\torch\\Lib\\site-packages\\langchain\\output_parsers\\pydantic.py:34\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     32\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpydantic_object\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m     33\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to parse \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from completion \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output\u001b[38;5;241m=\u001b[39mtext)\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Failed to parse GoogleSearch from completion {\n  \"properties\": {\n    \"search_terms\": [\n      \"points of view\",\n      \"keywords and/or phrases that are of high importance to the given content\"\n    ],\n    \"alternatives\": []\n  },\n  \"required\": [\"search_terms\"]\n}. Got: 2 validation errors for GoogleSearch\nsearch_terms\n  field required (type=value_error.missing)\nalternatives\n  field required (type=value_error.missing)"
     ]
    }
   ],
   "source": [
    "parser.parse(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2fe6dd4f-7563-400d-9f7a-52a52e4119f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GoogleSearch(search_terms=['point of view', 'perspective', 'opinion', 'view'], alternatives=['outlook', 'standpoint', 'stance', 'attitude'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_object = json.loads(output.content)\n",
    "parser.pydantic_object.parse_obj(json_object['properties'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999952e1-6d70-4e89-b66f-0425ba830431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
