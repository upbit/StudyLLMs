核心思想：微调过程增加8个复制的Decoder Block，能达到或超过MoE的性能
简评：通用思想，可以用于进一步补齐SFT在某类垂直领域数据下的能力

![[LLaMA-Pro.png]]

项目：[https://github.com/TencentARC/LLaMA-Pro](https://github.com/TencentARC/LLaMA-Pro)
讲解：[腾讯开源LlaMA Pro增强LLM性能 新方法，打造行业模型](https://www.bilibili.com/video/BV1Vi42197jN/)
